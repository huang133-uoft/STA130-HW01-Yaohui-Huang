{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5b9948",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3bc4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n",
      "age                  0\n",
      "workclass         1836\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education_num        0\n",
      "marital_status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital_gain         0\n",
      "capital_loss         0\n",
      "hours_per_week       0\n",
      "native_country     583\n",
      "income               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the column names, since the dataset does not have headers\n",
    "column_names = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "    'hours_per_week', 'native_country', 'income'\n",
    "]\n",
    "\n",
    "# Import the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "df = pd.read_csv(url, header=None, names=column_names, na_values=' ?')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display the columns with missing values and their counts\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01dd10e",
   "metadata": {},
   "source": [
    "#### Question 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c71e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 32561\n",
      "Number of columns: 15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "# Replace 'adult.data' with the path to your downloaded file if necessary\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "df = pd.read_csv(url, names=column_names, na_values=' ?', sep=',', skipinitialspace=True)\n",
    "\n",
    "# Display the number of rows and columns\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5de43f",
   "metadata": {},
   "source": [
    "#### Question 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8d403",
   "metadata": {},
   "source": [
    "Observations are specific data collected from observational units, which can be understand as a actual value for 'varaibles', and every individual obervation corresponds to a row in a tabular dataset.\n",
    "\n",
    "Variables stand for the groups of quantities or characteristics that can be measured and recorded. Variables can assumed by more than one value from observations, every variable corresponds to a column in a tabular dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9979b395",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5143830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics (Numerical):\n",
      "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
      "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
      "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
      "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
      "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
      "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
      "\n",
      "       hours-per-week  \n",
      "count    32561.000000  \n",
      "mean        40.437456  \n",
      "std         12.347429  \n",
      "min          1.000000  \n",
      "25%         40.000000  \n",
      "50%         40.000000  \n",
      "75%         45.000000  \n",
      "max         99.000000  \n",
      "\n",
      "Summary Statistics (All Columns):\n",
      "                 age workclass        fnlwgt education  education-num  \\\n",
      "count   32561.000000     32561  3.256100e+04     32561   32561.000000   \n",
      "unique           NaN         9           NaN        16            NaN   \n",
      "top              NaN   Private           NaN   HS-grad            NaN   \n",
      "freq             NaN     22696           NaN     10501            NaN   \n",
      "mean       38.581647       NaN  1.897784e+05       NaN      10.080679   \n",
      "std        13.640433       NaN  1.055500e+05       NaN       2.572720   \n",
      "min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
      "25%        28.000000       NaN  1.178270e+05       NaN       9.000000   \n",
      "50%        37.000000       NaN  1.783560e+05       NaN      10.000000   \n",
      "75%        48.000000       NaN  2.370510e+05       NaN      12.000000   \n",
      "max        90.000000       NaN  1.484705e+06       NaN      16.000000   \n",
      "\n",
      "            marital-status      occupation relationship   race    sex  \\\n",
      "count                32561           32561        32561  32561  32561   \n",
      "unique                   7              15            6      5      2   \n",
      "top     Married-civ-spouse  Prof-specialty      Husband  White   Male   \n",
      "freq                 14976            4140        13193  27816  21790   \n",
      "mean                   NaN             NaN          NaN    NaN    NaN   \n",
      "std                    NaN             NaN          NaN    NaN    NaN   \n",
      "min                    NaN             NaN          NaN    NaN    NaN   \n",
      "25%                    NaN             NaN          NaN    NaN    NaN   \n",
      "50%                    NaN             NaN          NaN    NaN    NaN   \n",
      "75%                    NaN             NaN          NaN    NaN    NaN   \n",
      "max                    NaN             NaN          NaN    NaN    NaN   \n",
      "\n",
      "        capital-gain  capital-loss  hours-per-week native-country income  \n",
      "count   32561.000000  32561.000000    32561.000000          32561  32561  \n",
      "unique           NaN           NaN             NaN             42      2  \n",
      "top              NaN           NaN             NaN  United-States  <=50K  \n",
      "freq             NaN           NaN             NaN          29170  24720  \n",
      "mean     1077.648844     87.303830       40.437456            NaN    NaN  \n",
      "std      7385.292085    402.960219       12.347429            NaN    NaN  \n",
      "min         0.000000      0.000000        1.000000            NaN    NaN  \n",
      "25%         0.000000      0.000000       40.000000            NaN    NaN  \n",
      "50%         0.000000      0.000000       40.000000            NaN    NaN  \n",
      "75%         0.000000      0.000000       45.000000            NaN    NaN  \n",
      "max     99999.000000   4356.000000       99.000000            NaN    NaN  \n",
      "\n",
      "Value Counts for 'education':\n",
      "education\n",
      "HS-grad         10501\n",
      "Some-college     7291\n",
      "Bachelors        5355\n",
      "Masters          1723\n",
      "Assoc-voc        1382\n",
      "11th             1175\n",
      "Assoc-acdm       1067\n",
      "10th              933\n",
      "7th-8th           646\n",
      "Prof-school       576\n",
      "9th               514\n",
      "12th              433\n",
      "Doctorate         413\n",
      "5th-6th           333\n",
      "1st-4th           168\n",
      "Preschool          51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing Values in Each Column:\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "income            0\n",
      "dtype: int64\n",
      "\n",
      "Unique Values in Each Column:\n",
      "age                  73\n",
      "workclass             9\n",
      "fnlwgt            21648\n",
      "education            16\n",
      "education-num        16\n",
      "marital-status        7\n",
      "occupation           15\n",
      "relationship          6\n",
      "race                  5\n",
      "sex                   2\n",
      "capital-gain        119\n",
      "capital-loss         92\n",
      "hours-per-week       94\n",
      "native-country       42\n",
      "income                2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "df = pd.read_csv(url, names=column_names, na_values=' ?', sep=',', skipinitialspace=True)\n",
    "\n",
    "# Overview of dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics (Numerical):\")\n",
    "print(df.describe())\n",
    "\n",
    "# Summary statistics for all columns\n",
    "print(\"\\nSummary Statistics (All Columns):\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Frequency counts for a specific column\n",
    "print(\"\\nValue Counts for 'education':\")\n",
    "print(df['education'].value_counts())\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Number of unique values\n",
    "print(\"\\nUnique Values in Each Column:\")\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821568bd",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0eb783",
   "metadata": {},
   "source": [
    "(a)\n",
    "The reason that the columns analyzed by df.describe() is much more fewer than the actual number of columns is becuase df.describe only summarizes numerical columns by default. When analyzing a dataset containing categorical columns, the categorical columns won't appear in the summary unless you specify \"include='all'\".\n",
    "\n",
    "(b)\n",
    "The reason for this discrepancy is due to missing values. The \"count\" column for the output of df.describe() represents the number of non-missing values for each columns. Therefore, whenever a column exist missing values, the \"count\" will deduct this value from the total number of rows in the Dataframe, which causes the discrepancy for the values reported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06492390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check the shape of the DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "# Summary statistics of numeric columns\n",
    "print(df.describe())\n",
    "\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d4d60",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d734c728",
   "metadata": {},
   "source": [
    "Attributes is a variable representing the proerties of an object that comes without parentheses. It provides a direct access to data and usually used to get or set values (for example: number of columns) that does not require any computation process.\n",
    "\n",
    "Method is a funcion to execute that comes with parentheses. It performs a action that may returns a result such as processing the data, which requires some level of processing and compution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97cf7a",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab85f42",
   "metadata": {},
   "source": [
    "Count: The number of non-null(NaN excluded) values in the column.\n",
    "\n",
    "Mean: Sum of all the values divided by \"count\", which represents the avaerage value of the column. (central trendency)\n",
    "\n",
    "STD: Standard deviation is 'the quare root of the average of the squared differences between each value and the mean', which is a measure of the dispersion or spread of the values in the column.\n",
    "\n",
    "Min: Minimum is the smallest value in the column.\n",
    "\n",
    "25%: The value below which 25% of the data points fall, also known as Q1.(25% values lie under this line)\n",
    "\n",
    "50%: Median is the middle value of the column when all values are sorted in ascending order.\n",
    "\n",
    "75%: The value below which 75% of the data points fall, also known as Q3.\n",
    "\n",
    "Max: Maximum is the greatest value in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1302fc",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152489ae",
   "metadata": {},
   "source": [
    "(a)\n",
    "df.dropna() is perferred when you want to analyze only the complete data, since it helps to remove rows or colomns with missing value.\n",
    "\n",
    "(b)\n",
    "In contrast, del df['col'] is perferred when you want to remove an entire column from the dataFrame, which might cause the lost of potentially valuable data.\n",
    "\n",
    "(c)\n",
    "There are three main reasons make it important to apply del df['col'] first, including prevent the loss of useful data in rows, reduce the stress of analysis by reduing the size of the DataFrame and also helps maintain a better data proprocessing logic.\n",
    "\n",
    "(d)\n",
    "This is a combination of two df.dropna. The first step is applied todrop columns with sinificant missing data more than 30% in order to retain the informative parts of the dataset. The second step is used to drop rows with remaining missing data from the first setp, which ensures the dataset is clean for analyze. Before cleaning the dataset, the data shape is (891, 15); and after the cleaning, the data shape remians (712, 14). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1773f24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data (before):\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "Missing data (after):\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n",
      "\n",
      "Data shape before cleaning: (891, 15)\n",
      "Data shape after cleaning: (712, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Before: Check the number of missing values in each column\n",
    "missing_data_before = df.isna().sum()\n",
    "print(\"Missing data (before):\")\n",
    "print(missing_data_before)\n",
    "\n",
    "# Step 1: Drop columns with more than 30% missing values\n",
    "threshold = len(df) * 0.3\n",
    "df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Step 2: Drop rows with any remaining missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# After: Check the number of missing values in each column\n",
    "missing_data_after = df_cleaned.isna().sum()\n",
    "print(\"\\nMissing data (after):\")\n",
    "print(missing_data_after)\n",
    "\n",
    "# Before and after shape comparison\n",
    "print(\"\\nData shape before cleaning:\", (891, 15))\n",
    "print(\"Data shape after cleaning:\", df_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3484f72",
   "metadata": {},
   "source": [
    "#### Question 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03cc88c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "             count       mean        std   min    25%   50%   75%   max\n",
      "embark_town                                                            \n",
      "Cherbourg    130.0  30.814769  15.434860  0.42  21.25  29.0  40.0  71.0\n",
      "Queenstown    28.0  28.089286  16.915396  2.00  17.50  27.0  34.5  70.5\n",
      "Southampton  554.0  29.445397  14.143192  0.67  21.00  28.0  38.0  80.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "result = df.groupby(\"embark_town\")[\"age\"].describe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc1937",
   "metadata": {},
   "source": [
    "#### Question 8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97771c0",
   "metadata": {},
   "source": [
    "First, df.describe() provides data for the entire column across all rows, which df.groupby(\"col1\")[\"col2\"].describe()for a column whthin groups defined by another column. Secondly, df.describe() shows all non-null values in the dataset. Thirdly, df.groupby(\"col1\")[\"col2\"].describe() helps processing data with specific subsets rather than df.describe()provides a overall sense of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246ca17",
   "metadata": {},
   "source": [
    "#### Question 8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a52b6",
   "metadata": {},
   "source": [
    "ChatBots such as Chatgpt are much more reliable on fixing error when coding comparing to Google search. Their advantage is to analyze the specific codes we are dealing with and give instructions in direct and precise ways immediately. The biggest problem of using Google search is it always give a long-winded expalinanation, and it's much more inefficient.\n",
    "\n",
    "\n",
    "A. \n",
    "Both Chatgpt and Google search gives the troubleshooting help quickly and precisely. Since the Chatbot gives the fixed coding direclty, it solves this error more quickly. \n",
    "\n",
    "B. \n",
    "Both Chatgpt and Google search finds the error and gives the instruction of cheking the URL at the first time.\n",
    "\n",
    "C. \n",
    "Google gives the troubleshoot slower that Chatgpt. Chatgpt gives the instruction to check variable definition at the very beginning but Google does not.\n",
    "\n",
    "D. \n",
    "Both Chatgpt and Google gives the right insturction, but Chatgpt is much more quickly and direclty.\n",
    "\n",
    "E.\n",
    "Chatgpt solves the error directly but Google does not provide the right method.\n",
    "\n",
    "F.\n",
    "Chatgpt gives the solution at the first step, and Google's answers are much more complex.\n",
    "\n",
    "G.\n",
    "Chatgpt gives instruction which are more clearly to fix this error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc607ff",
   "metadata": {},
   "source": [
    "#### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24ca8d",
   "metadata": {},
   "source": [
    "Yes. I did review those materials, but is doesn't helps that much to understand quckily, since I have no former experiences or knowledges with related contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9667282",
   "metadata": {},
   "source": [
    "#### Chatlog history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce188a9",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/06e5e524-267a-45ce-8dd3-498efde8c859\n",
    "\n",
    "Summary:\n",
    "\n",
    "1. Dataset Introduction:\n",
    "Adult (Census Income) Dataset: A dataset from the UCI Machine Learning Repository used for predicting income levels based on various demographic and economic attributes. It contains 48,842 records and 14 attributes.\n",
    "2. Determining Dataset Dimensions:\n",
    "To find the number of rows and columns in a pandas DataFrame, use df.shape which returns a tuple (rows, columns).                 \n",
    "3. Observation in the Dataset:\n",
    "An observation is a single individual's record, including various attributes like age, workclass, and income level.\n",
    "4. Variable in the Dataset:\n",
    "A variable (or feature) represents a specific characteristic of the data. In the Adult dataset, examples include age, workclass, education, and income.\n",
    "5. Summarizing Dataset Columns:\n",
    "df.describe(): Provides a summary of numerical columns (mean, standard deviation, min, max).                   \n",
    "df.describe(include='object'): Summarizes categorical columns (unique values, top category, frequency).        \n",
    "df.info(): Gives data types and missing values.                                                               \n",
    "df.value_counts(): Shows frequency of categories in a specific column.                                        \n",
    "df.nunique(): Shows the number of unique values in each column.                                              \n",
    "df.agg(): Allows for custom aggregations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0077a8",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6468a503-bd4b-44c6-9026-35a37f9d6a85 \n",
    "\n",
    "The chat discusses why there is a difference between the dataset size shown by `df.shape` and the columns analyzed by `df.describe()`. The reason is that `df.describe()` only includes numeric columns by default, excluding non-numeric ones.\n",
    "Next, a method to remove missing data from the Titanic dataset is provided: first, drop columns with a high percentage of missing values, then drop any remaining rows with missing data. This approach helps ensure a clean dataset for analysis. The explanation includes the steps and rationale, though executing the code was not possible due to a network issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4076d39",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/672a5d12-499f-462d-935e-0abb54300bc1\n",
    "\n",
    "Summary:\n",
    "\n",
    "1. Overview of the Dataset:                                                                         \n",
    "Dataset URL: Adult Income Dataset                                                                      \n",
    "The dataset contains demographic information and income levels.                                            \n",
    "2. Key Concepts:\n",
    "Attributes vs. Methods:                                                                                         \n",
    "Attributes (e.g., df.shape): Variables that provide information about the object without parentheses.         \n",
    "Methods (e.g., df.describe()): Functions that perform actions on the object and require parentheses to call.   \n",
    "Summary Statistics in df.describe():                                                                          \n",
    "Count: Number of non-null entries.                          \n",
    "Mean: Average value.                                                                       \n",
    "Standard Deviation (std): Measure of dispersion. \n",
    "Min: Smallest value.                                                                     \n",
    "25%: 25th percentile value.                                               \n",
    "50% (Median): Middle value.                                                                                   \n",
    "75%: 75th percentile value.                                                                                    \n",
    "Max: Largest value.                                                                                     \n",
    "3. Handling Missing Data: \n",
    "df.dropna(): Removes rows (or columns) with missing values.                                                    \n",
    "del df['col']: Deletes entire columns.           \n",
    "4. Example Approach to Cleaning Data: \n",
    "Step 1: Load the dataset and identify missing values.                                                      \n",
    "Step 2: Remove columns with excessive missing values.                                                       \n",
    "Step 3: Use df.dropna() to remove rows with any remaining missing values.                                   \n",
    "Step 4: Report the shape and missing values before and after cleaning.                                       \n",
    "5. Justification: \n",
    "Using del df['col']: Preferred for removing columns with too many missing values to retain valuable data.      \n",
    "Using df.dropna(): Ensures that the remaining rows are complete, suitable for analysis without missing data issues.  \n",
    "6. Example Results: \n",
    "Before Cleaning: The dataset had missing values in several columns.                                            \n",
    "After Cleaning: The dataset had no missing values, with changes in the shape of the DataFrame reflecting the removal of incomplete rows or columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb35477",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/014118a8-736a-42c6-b2c2-2fab88c3b2d7\n",
    "\n",
    "Summary:\n",
    "\n",
    "1. df.dropna() vs. del df['col']:                                                   \n",
    "df.dropna(): Removes rows with missing values.\n",
    "del df['col']: Deletes a specific column.\n",
    "2. Combining Both:\n",
    "Deleting a column before removing rows can be useful if the column has many missing values.               \n",
    "df.groupby(\"col1\")[\"col2\"].describe():\n",
    "Groups data by col1 and provides statistics for col2 within each group.\n",
    "3. Error Handling:\n",
    "NameError: Check if the variable is defined and correctly named.                       \n",
    "HTTPError 404: Verify the URL or try a different source.                       \n",
    "SyntaxError: Check for unclosed parentheses.                             \n",
    "AttributeError: Use the correct method name, describe.                               \n",
    "KeyError: Ensure the column name exists and is correctly spelled.                   \n",
    "NameError for column: Use column names as strings, not variables.                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0d3117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
